name: AKS - Deploy Services to AKS
run-name: >
  Deploy to ${{
    inputs.environment_name != '' && format('custom:{0}', inputs.environment_name) ||
    github.event.inputs.environment_name != '' && format('custom:{0}', github.event.inputs.environment_name) ||
    'dev'
  }} [${{ inputs.environment || github.event.inputs.environment }}]

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Select environment (GitHub Environment)'
        required: true
        default: 'Development'
        type: choice
        options: [Development, Production]
      environment_name:
        description: 'Optional namespace (lowercase letters & digits). Empty -> dev'
        required: false
        default: ''
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      environment_name:
        required: false
        type: string
    outputs:
      app_url:
        description: "Full URL of the deployed load balancer service"
        value: ${{ jobs.deploy.outputs.app_url }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment || github.event.inputs.environment }}
    permissions:
      id-token: write
      contents: read

    outputs:
      app_url: ${{ steps.extract_url.outputs.app_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login via OIDC
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Set up variables
        run: |    
          ENVIRONMENT_NAME="${{ inputs.environment_name || github.event.inputs.environment_name }}"
          
          if [ -n "$ENVIRONMENT_NAME" ]; then
            if [[ ! "$ENVIRONMENT_NAME" =~ ^[a-z0-9]+$ ]]; then
              echo "environment_name must be lowercase letters and digits only (^[a-z0-9]+$)"; exit 1
            fi
            echo "TARGET_NAMESPACE=$ENVIRONMENT_NAME" >> $GITHUB_ENV
            echo "VALUES_FILE=devops/kubernetes/charts/values.dev.yaml" >> $GITHUB_ENV
            echo "RESOLVED_TARGET=custom($ENVIRONMENT_NAME)" >> $GITHUB_ENV
          else
            echo "TARGET_NAMESPACE=dev" >> $GITHUB_ENV
            echo "VALUES_FILE=devops/kubernetes/charts/values.dev.yaml" >> $GITHUB_ENV
            echo "RESOLVED_TARGET=dev" >> $GITHUB_ENV
          fi
          
          echo "K8S_DIR=devops/kubernetes/" >> $GITHUB_ENV
          echo "CHART_DIR=devops/kubernetes/charts" >> $GITHUB_ENV
          echo "DOCKER_REGISTRY=${{ secrets.DOCKER_USERNAME }}" >> $GITHUB_ENV
          echo "OPENAI_KEY=${{ secrets.AZURE_OPENAI_API_KEY }}" >> $GITHUB_ENV
          echo "AZURE_SPEECH_KEY=${{ secrets.AZURE_SPEECH_KEY }}" >> $GITHUB_ENV
          echo "PG_DB=${ENVIRONMENT_NAME}-pg-zionet-learning" >> $GITHUB_ENV
          echo "PG_RG=${ENVIRONMENT_NAME}-zionet-learning-2025" >> $GITHUB_ENV

          
          # Now we use only dev as the shared AKS cluster
          echo "AKS_RG=dev-zionet-learning-2025" >> $GITHUB_ENV
          echo "MC_AKS_RG=MC_dev-zionet-learning-2025_aks-cluster-dev_westeurope" >> $GITHUB_ENV
          echo "AKS_NAME=aks-cluster-dev" >> $GITHUB_ENV

      - name: Get AKS credentials
        run: |
          az aks get-credentials --resource-group $AKS_RG --name $AKS_NAME --overwrite-existing

      - name: Install/Upgrade Dapr control plane
        run: |
          cd devops/helm-tools
          chmod +x dapr-control-plane.sh
          ./dapr-control-plane.sh

      - name: Ensure target namespace exists
        run: |
          kubectl create namespace "$TARGET_NAMESPACE" --dry-run=client -o yaml | kubectl apply -f -

      - name: Ensure baseline secrets exist in target namespace
        run: |
          set -e
          sudo apt-get update -y >/dev/null
          sudo apt-get install -y jq >/dev/null
          ns="$TARGET_NAMESPACE"

          make_secret () {
            local name="$1"; shift
            if kubectl -n "$ns" get secret "$name" >/dev/null 2>&1; then
              echo "✓ $name already exists in $ns"; return
            fi
            if kubectl -n dev get secret "$name" >/dev/null 2>&1; then
              echo "Copying $name from dev -> $ns"
              kubectl -n dev get secret "$name" -o json \
              | jq 'del(.metadata.uid,.metadata.resourceVersion,.metadata.creationTimestamp,.metadata.managedFields,.metadata.annotations)
                    | .metadata.namespace="'$ns'"' \
              | kubectl apply -f -
              echo "✓ Copied $name"; return
            fi
            echo "Creating $name in $ns from repo secrets"
            "$@"
          }

          make_secret azure-service-bus-secret \
            kubectl -n "$ns" create secret generic azure-service-bus-secret \
              --from-literal=AzureServiceBusConnectionString='${{ secrets.AZURE_SERVICEBUS_CONNECTION_STRING }}' \
              --dry-run=client -o yaml | kubectl apply -f -

          make_secret postgres-connection \
            kubectl -n "$ns" create secret generic postgres-connection \
              --from-literal=PostgreSQLConnectionString='${{ secrets.POSTGRES_CONNECTION_STRING }}' \
              --dry-run=client -o yaml | kubectl apply -f -

          make_secret redis-connection \
            kubectl -n "$ns" create secret generic redis-connection \
              --from-literal=redis-hostport='${{ secrets.REDIS_HOSTPORT }}' \
              --from-literal=redis-password='${{ secrets.REDIS_PASSWORD }}' \
              --dry-run=client -o yaml | kubectl apply -f -

          make_secret signalr-connection \
            kubectl -n "$ns" create secret generic signalr-connection \
              --from-literal=AzureSignalRConnectionString='${{ secrets.AZURE_SIGNALR_CONNECTION_STRING }}' \
              --dry-run=client -o yaml | kubectl apply -f -

      - name: Helm upgrade/install services
        run: |
          helm template app "$CHART_DIR" -f "$VALUES_FILE" \
            --set namespace.name="$TARGET_NAMESPACE" \
            --set namespace.create=false \
            --set global.namePrefix="$TARGET_NAMESPACE" \
            --set global.dockerRegistry="$DOCKER_REGISTRY" \
            --set-string engine.env.AzureOpenAI__ApiKey="$OPENAI_KEY" \
            --set-string engine.env.AzureSpeech__SubscriptionKey="$AZURE_SPEECH_KEY" \
            --set dapr.installComponents=false \
          | grep -n '^kind: Namespace' && { echo "Namespace still rendered"; exit 1; } || echo "OK: no Namespace in chart"

          helm upgrade --install app "$CHART_DIR" \
            --namespace "$TARGET_NAMESPACE" \
            -f "$VALUES_FILE" \
            --set namespace.name="$TARGET_NAMESPACE" \
            --set namespace.create=false \
            --set global.namePrefix="$TARGET_NAMESPACE" \
            --set global.dockerRegistry="$DOCKER_REGISTRY" \
            --set-string engine.env.AzureOpenAI__ApiKey="$OPENAI_KEY" \
            --set-string engine.env.AzureSpeech__SubscriptionKey="$AZURE_SPEECH_KEY" \
            --set dapr.installComponents=false \
            --atomic --timeout 10m

      - name: Wait for deployments ready
        run: |
          ns="$TARGET_NAMESPACE"
          kubectl -n "$ns" rollout status deploy/manager --timeout=5m
          kubectl -n "$ns" rollout status deploy/engine  --timeout=5m
          kubectl -n "$ns" rollout status deploy/accessor --timeout=5m

      - name: Diagnostics (on failure)
        if: failure()
        run: |
          ns="$TARGET_NAMESPACE"
          echo "---- Objects ----"
          kubectl -n "$ns" get all
          echo
          echo "---- Events (recent) ----"
          kubectl -n "$ns" get events --sort-by=.lastTimestamp | tail -n 200 || true
          echo
          echo "---- Pod details ----"
          for p in $(kubectl -n "$ns" get pods -o name); do
            echo "## $p"
            kubectl -n "$ns" describe "$p" || true
            echo "-- logs (last 200 lines, all containers) --"
            kubectl -n "$ns" logs "$p" --all-containers --tail=200 || true
            echo
          done
          
      - name: setup-ingress-controller
        run: |
          cd devops/helm-tools
          chmod +x setup-ingress-controller.sh
          ./setup-ingress-controller.sh

      - name: Add grafana
        run: |
          cd devops/helm-tools
          chmod +x grafana.sh
          ./grafana.sh

      - name: Setup HTTPS certificates
        run: |
          cd devops/helm-tools
          chmod +x setup-https.sh
          ./setup-https.sh   

      - name: Apply Grafana ingress (only)
        run: kubectl apply -f "$K8S_DIR/ingress/grafana-ingress.yaml"

      - name: Add prometheus
        run: |
          cd devops/helm-tools/prometheus
          chmod +x prometheus.sh
          ./prometheus.sh

      - name: Add Loki (logs stack)
        run: |
          cd devops/helm-tools/loki
          chmod +x loki.sh
          ./loki.sh
    
    
      - name: Wait for external IP for ingress controller
        id: wait_for_ingress_ip
        run: |
          echo "Waiting for external IP for ingress-nginx-controller..."
          for i in {1..30}; do
            INGRESS_IP=$(kubectl -n devops-ingress-nginx get svc ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [[ -n "$INGRESS_IP" ]]; then
              echo "Ingress IP is ready: $INGRESS_IP"
              echo "ingress_url=http://$INGRESS_IP" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "Attempt $i: Ingress IP not yet assigned. Waiting 10s..."
            sleep 10
          done
          echo "Failed to get ingress IP after waiting. Check 'kubectl get svc ingress-nginx-controller -n devops-ingress-nginx'"
          exit 1
      

      - name: Add ingress IP to PostgreSQL firewall
        run: |
          INGRESS_IP=$(kubectl -n devops-ingress-nginx get svc ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          az postgres flexible-server firewall-rule create \
            --resource-group $PG_RG \
            --name $PG_DB \
            --rule-name allow-ingress-controller \
            --start-ip-address $INGRESS_IP \
            --end-ip-address $INGRESS_IP
            
    
      - name: Restart all pods in the namespace
        run: |
          kubectl delete pod --all -n "$TARGET_NAMESPACE"


      - name: Output external URL
        id: extract_url
        run: |
          echo "app_url=${{ steps.wait_for_ingress_ip.outputs.ingress_url }}" >> $GITHUB_OUTPUT
          echo "App URL: ${{ steps.wait_for_ingress_ip.outputs.ingress_url }}"